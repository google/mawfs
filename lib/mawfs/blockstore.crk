# Copyright 2016 Google Inc. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

## Low-level block-store API.

#import crack.exp.fuse fuseMain = main, LockedFilesystem, NodeImpl;
import crack.cont.array Array;
import crack.enc.base64 altDecode, altEncode;
import crack.hash Hash;
import crack.hash.sha256 SHA256;
import crack.io StringReader;
import crack.lang cmp, makeHashVal, AppendBuffer, Buffer, Exception,
    InvalidArgumentError, ManagedBuffer;
import crack.logger debug;
import crack.serial SerialReader, SerialWriter;

import crack.fs Path;
import crack.io FStr, Reader, StringWriter, Writer;

import crack.protobuf readMessageFromString, Field, Message, ProtoWriter;
import crack.crypt.ssl.cipher EVP_aes_256_cbc, DecryptWriter, EncryptWriter;

@import crack.ann interface, impl;
@import crack.protobuf.ann protobuf;

const MAX_NODE_SIZE := 1024 * 1024;

const int
    MODE_DIR = 1,   # A directory.
    MODE_EXE = 2;   # Set the executable flag.

@protobuf {
    ## A filesystem entry.  Nodes can either be directories or blobs.
    ## Directories have a mode of MODE_DIR and their entries all have name
    ## attributes.  Blobs do not have MODE_DIR and their entries all have
    ## sizes, the size being the total size of the contents of the subtree
    ## under that entry.
    message Entry {
        ## The sha256 hash of the encrypted object.
        optional bytes hash = 1;

        ## The name of the object (for a directory entry).
        optional string name = 2;

        ## The 32 bit checksum of the original file (calculated by adding
        ## bytes).
        optional int32 org_checksum = 3;

        ## The size of the total contents of the subtree (for a blob entry).
        optional uint64 size = 4;
    }

    ## A filesystem node.  MAWFS is agnostic to the difference between files
    ## and directories.  A MAWFS node can contain both named entries and
    ## contents.
    message Node {
        required int32 checksum = 1;
        optional string contents = 2;

        ## 'size' is the size of the data in all children.
        optional uint64 size = 4;
        repeated Entry children = 3;

        ## See the MODE_* constants above.  'mode' should be present for all
        ## top-level file nodes and directory nodes.
        optional int32 mode = 5;

# Recursively defined protobufs don't seem to work.  And anyway, we really
# to store the digests of the elements, not the nodes themselves.
#        repeated Node elems = 4;
    }

    ## A commit.  These objects track the history of an entire filesystem.
    message Commit {
        ## The digest of the "parent" commits.  There should generally be one
        ## of these.
        ## The first tree of the filesystem will have no parents.
        ## A "merge" commit (which merges two filesystems) will have more than
        ## one parent.
        repeated bytes parent = 1;

        ## The digest of the root of the filesystem at the point of the commit.
        optional bytes root = 2;
    }

    ## Change is like a lightweight Commit for purposes of storing changes in
    ## the filesystem journal.
    message Change {
        ## Types are the CHANGE_* constants.
        required int32 type = 1;

        ## List of child indexes representing a path to the node to be
        ## modified.
        repeated int32 path = 10;

        ## Child name.
        optional string name = 2;

        ## Node to be added.
        optional Node node = 3;

        ## Change to be applied to a nested child (should be another Changes
        ## message).
        optional bytes nested = 4;

        ## Position to insert data into for a write.
        optional uint64 pos = 5;

        ## Data to be inserted in a write.
        optional bytes data = 6;

        ## New size of the node for a resize.
        optional uint64 newSize = 7;

        ## The digest of the last Change.  Every change should have this
        ## except for the first change after a commit, which should have a
        ## 'commit' field.
        optional bytes lastChange = 8;

        ## The commit that this change should be applied to.  Only the first
        ## change after a commit should have this field, all others should
        ## have 'lastChange' instead.
        optional bytes commit = 9;

        # last tag: 10
    }
}

String hashFile(Path file) {
    src := file.makeFullReader();
    hasher := SHA256();
    buffer := ManagedBuffer(4096);
    uint64 size;
#    while (rc := src.read(buffer)) {
#        size += rc;
#        cout `\r$size\033[k`;
#        hasher.update(buffer);
#    }
    hasher.update(src.readAll());
    return hasher.digest();
}

## A chunk is the basic unit of data in MAWFS.  We store its content and
## the digest of its encrypted representation.
class Chunk {
    String contents;
    String digest;

    oper init(String contents, String digest) :
        contents = contents,
        digest = digest {
    }
}

# Size of blocks to read and write.
const BLOCK_SIZE := 65536;

class BadDigestError : Exception {
    oper init() {}
    oper init(String message) : Exception(message) {}
}

class HashAndWrite @impl Writer {

    Hash hasher;
    Writer dst;

    oper init(Hash hasher, Writer dst) :
        hasher = hasher,
        dst = dst {
    }

    void write(Buffer data) {
        hasher.update(data);
        dst.write(data);
    }

    String getDigest() { return hasher.digest(); }
}

## Information on a MAWFS filesystem.
class FSInfo {
    String password;

    oper init(String password) : password = password {}

    ## Reads a "Chunk" from a Reader.  A chunk is the basic unit of data.  The
    ## reader is assumed to be an encrypted stream
    Chunk readChunk(Reader src) {
        hasher := SHA256();
        back := StringWriter();
        decrypter := DecryptWriter(EVP_aes_256_cbc(), password, back);
        while (data := src.read(BLOCK_SIZE)) {
            hasher.update(data);
            decrypter.write(data);
        }

        decrypter.close();

        return Chunk(back.string(), hasher.digest());
    }

    ## Writes and encrypts raw chunk data, returns the digest of the encrypted
    ## data.
    String writeChunk(Writer dst, Buffer data) {
        temp := Buffer(null, 0);
        uint cur;
        HashAndWrite back = {SHA256(), dst};
        encrypter := EncryptWriter(EVP_aes_256_cbc(), password, back);
        while (cur < data.size) {
            temp.size = (data.size - cur > BLOCK_SIZE) ? BLOCK_SIZE :
                                                         data.size - cur;
            temp.buffer = data.buffer + cur;
            encrypter.write(temp);
            cur += temp.size;
        }

        encrypter.close();
        return back.getDigest();
    }

    ## Writes and encrypts a chunk and verifies the digest.  If the digest
    ## doesn't match that of the chunk, throws a BadDigestError.
    void writeChunk(Writer dst, Chunk chunk) {
        if (writeChunk(dst, chunk.contents) != chunk.digest)
            throw BadDigestError();
    }
}

class ChangeEntry {
    String digest;
    Change change;

    oper init(String digest, Change change) :
        digest = digest,
        change = change {
    }
}

@interface JournalIter {
    @abstract ChangeEntry elem();
    @abstract void next();

    JournalIter iter() { return this; }
}

## Interface for a node store.
@interface NodeStore {

    ## Store a chunk, return its digest.
    @abstract String storeNode(Node node);

    ## Get the node at the given digest, null if it's not currently stored.
    @abstract Node getNode(String digest);

    ## Stores a Commit, returns its digest.
    @abstract String storeCommit(Commit commit);

    ## Retrieves a commit object from its digest, null if it's not currently
    ## stored.
    @abstract Commit getCommit(String digest);

    # Get the root node (null if there is no root).
    @abstract Node getRoot();

    # Get the root digest (null if there is no root).
    @abstract String getRootDigest();

    ## Store the digest of the root node.
    @abstract void storeRoot(String digest);

    ## Returns the digest of the head commit of a given branch.   Returns
    ## null if the branch is not defined.
    @abstract String getHead(String branch);

    ## Sets the digest of the head commit for the branch.
    @abstract void setHead(String branch, String digest);

    ## Write a change to the journal for the branch.  Returns the digest of
    ## the change.
    @abstract String writeToJournal(String branch, Change change);

    ## Delete the journal for a node.
    @abstract void deleteJournal(String branch);

    ## Return an iterator over the journal
    @abstract JournalIter makeJournalIter(String branch);
}

## Lets you store and load chunks from a persistent back-end.
## This is currently implemented as a thin wrapper around a directory, but it
## should eventually be an interface wrapping any place fine chunks are
## stored.
class ChunkStore @impl NodeStore {

    Path __dir;
    FSInfo __fsInfo;

    oper init(Path dir, FSInfo fsInfo) : __dir = dir, __fsInfo = fsInfo {}

    ## Loads and returns the chunk with the specified digest, returns null if
    ## the chunk doesn't exist in the store.
    ##
    ## Verifies the chunk digest on read, throws BadDigestError if it doesn't
    ## match.
    Chunk load(String digest) {
        path := __dir/'objects'/altEncode(digest);
        if (path.exists()) {
            result := __fsInfo.readChunk(path.reader());
            if (result.digest != digest)
                throw BadDigestError(
                    FStr() I`chunk $(altEncode(digest)) data integrity failure.
                             Actual data digest is $(altEncode(result.digest))`
                );
            return result;
        } else {
            return null;
        }
    }

    Path __objectsDir() {
        objectsDir := __dir/'objects';
        if (!objectsDir.exists())
            objectsDir.makeDir();
        return objectsDir;
    }

    ## Store the chunk.
    ##
    ## Verifies the chunk digest on write, throws BadDigestError if it doesn't
    ## match.
    void store(Chunk chunk) {
        path := __objectsDir()/altEncode(chunk.digest);
        __fsInfo.writeChunk(path.writer(), chunk);
    }

    ## Stores a chunk without a hash.  Returns the digest.
    String store(Buffer data) {
        path := __objectsDir()/(FStr() `tempchunk.$(uintz(data))`);
        digest := __fsInfo.writeChunk(path.writer(), data);
        path.moveTo(__objectsDir()/altEncode(digest));
        return digest;
    }

    Node getNode(String digest) {
        chunk := load(digest);
        if (!chunk)
            return null;

        Node node = {};
        readMessageFromString(node, chunk.contents);
        return node;
    }

    ## Stores the node, returns its digest.
    String storeNode(Node node) {
        return store(node.toString());
    }

    Commit getCommit(String digest) {
        chunk := load(digest);
        if (!chunk)
            return null;

        Commit commit = {};
        readMessageFromString(commit, chunk.contents);
        return commit;
    }

    String storeCommit(Commit commit) {
        return store(commit.toString());
    }

    ## Returns the root node or null if there is none.
    Node getRoot() {
        rootFile := __dir/'refs/root';
        if (!rootFile.exists())
            return null;
        digest := altDecode(rootFile.readAll());
        return getNode(digest);
    }

    String getRootDigest() {
        rootFile := __dir/'refs/root';
        if (!rootFile.exists())
            return null;
        return altDecode(rootFile.readAll());
    }

    # Store the current root digest.
    void storeRoot(String digest) {
        (__dir/'refs/root').writeAll(altEncode(digest));
    }

    String writeToJournal(String branch, Change change) {
        journalDir := __dir/'journals';
        if (!journalDir.exists())
            journalDir.makeDirs();
        journalFile := journalDir/branch;
        Writer writer;
        if (journalFile.exists())
            writer = journalFile.appender();
        else
            writer = journalFile.writer();
        dst := SerialWriter(writer);

        # Encrypt the data into the buffer.
        StringWriter tmp = {};
        digest := __fsInfo.writeChunk(tmp, change.toString());

        # We can just write this directly to the SerialWriter.
        dst.write(tmp);

        return digest;
    }

    void deleteJournal(String branch) {
        file := __dir/'journals'/branch;
        if (file.exists())
            file.delete();
    }

    class __JIter @impl JournalIter {
        SerialReader __src;
        ChangeEntry __cur;
        FSInfo __fsInfo;

        void __readOne() {

            # Read the next entry, we're done if we run out of data.
            buf := __src.readString(false);
            if (!buf) {
                __cur = null;
                return;
            }

            chunk := __fsInfo.readChunk(StringReader(buf));
            Change change = {};
            readMessageFromString(change, chunk.contents);
            __cur = ChangeEntry(chunk.digest, change);
        }

        oper init(Reader src, FSInfo fsInfo) : __src(src), __fsInfo = fsInfo {
            __readOne();
        }
        ChangeEntry elem() { return __cur }
        void next() { __readOne(); }
        bool isTrue() { return __cur }
    }

    class __NullJIter @impl JournalIter {
        ChangeEntry elem() { return null }
        void next() {}
        bool isTrue() { return false }
    }

    JournalIter makeJournalIter(String branch) {
        src := __dir/'journals'/branch;
        if (!src.exists())
            return __NullJIter();
        return __JIter(src.reader(), __fsInfo);
    }

    Array[String] getJournalEntries(String digest) {
        return null;
    }

    String getHead(String branch) {
        branchFile := __dir/'refs'/branch;
        if (!branchFile.exists())
            return null;
        return altDecode(branchFile.readAll());
    }

    void setHead(String branch, String digest) {
        branchFile := __dir/'refs'/branch;
        if (!branchFile.parent().exists())
            branchFile.parent().makeDirs();
        branchFile.writeAll(altEncode(digest));
    }

    ## Store an entire directory in the blockstore.  Returns its digest.
#    String storeDir(Path root) {
#        files := Array[Entry]![];
#        for (file :in root.children()) {
#            if (file.isDir()) {
#                storeDir(file);
#            } else {
#                files.append(Entry
}
